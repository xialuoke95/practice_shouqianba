{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb22397d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "DeepCTR version 0.8.7 detected. Your version is 0.8.5.\n",
      "Use `pip install -U deepctr` to upgrade.Changelog: https://github.com/shenweichen/DeepCTR/releases/tag/v0.8.7\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/bytedance/LearningProjects/practice_shouqianba')\n",
    "sys.path.insert(0, '/Users/bytedance/LearningProjects/DeepCTR')\n",
    "\n",
    "from test_deepctr import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18c94931",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/bytedance/LearningProjects/dataset/movielens_sample.txt\")\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e935fe97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4627, 2496, 3630,  366, 1285, 5964, 4566, 4094, 1010, 2181,  506,\n",
       "       2943, 1680, 4964, 1408, 4214, 4732, 2820,  635, 3590, 1601, 1283,\n",
       "        716,  854, 3808, 5848, 3471, 2857, 4655, 4694, 4227, 5293,  829,\n",
       "       3312, 5512, 2837, 2533,  678, 2753, 4284, 1706,  872, 3675,  615,\n",
       "       4815, 1667, 1834, 2023, 1589, 2744, 3710, 1106, 5156, 2346, 5153,\n",
       "       3618, 1866, 1472, 1120, 3483, 3558,  182, 3947, 1836, 1861, 3053,\n",
       "       1884,  621,  785, 1685,  249, 2077, 5256, 4520, 2073, 3299, 2271,\n",
       "       4947, 4725,  613, 2996, 1303, 2211, 5893, 6036, 3045, 5732, 4658,\n",
       "       2174, 1755, 3274, 2590, 3123,   80, 1321,  753, 5389, 1841, 3589,\n",
       "       1717, 3762, 2913, 4205, 1141, 4290, 1579, 3679, 2230, 1265, 1941,\n",
       "       1391,  415, 4802, 6040, 4384, 5365, 1776,  471, 1591, 5831, 4973,\n",
       "       2841, 4645, 3184, 3087, 3402,  425, 1869, 1724,  974, 3401, 1383,\n",
       "       3436, 2050, 5720, 1015,  192, 4238, 5355, 2695, 3410,  284, 1164,\n",
       "       3759, 1868, 5521,  910, 5626, 1908, 1078, 5056, 1835,   76, 1427,\n",
       "       4966, 3526, 5953, 1246])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(train['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7850c39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 877, 4238, 1579, 2002,  881, 3242, 1752, 3910, 1391, 3705, 3315,\n",
       "       3430, 4502, 5080, 5630, 1503, 3568, 1273, 2438, 5157,  546, 2067,\n",
       "       5788, 5511, 2600, 5108, 5039, 5227, 2996, 4738, 4715,  517, 4889,\n",
       "       5767, 4373, 5371,  380, 5746, 5365, 3868])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(test['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dec58fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=13, shape=(), dtype=int32, numpy=6>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.add_n([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0c71a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dnn_feature_columns = [\n",
    "    SparseFeat(\"movie_id\", len(pd.unique(data[\"movie_id\"])), embedding_dim=16, use_hash=True),\n",
    "    SparseFeat(\"user_id\", len(pd.unique(data[\"user_id\"])), embedding_dim=16, use_hash=True),\n",
    "]\n",
    "linear_feature_columns = dnn_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18780375",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = get_feature_names(dnn_feature_columns + linear_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43fe2f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eee5f2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2478, 1278, 3256, 1077, 1794,  454, 3683,  529, 2953, 2020, 3354,\n",
       "       1197, 1988, 2348,  198, 3186, 3016,  457, 1270, 2000, 1396,  480,\n",
       "        737,  345,   61,  909, 3614,  436, 2146,  159, 3635, 1374,  904,\n",
       "        520, 1801, 2396, 2266, 1972, 3045,  517, 1916, 3092,  532,  296,\n",
       "       3181, 1240, 2288, 1012, 2594,  588, 3033, 3624, 3688, 1416, 1290,\n",
       "       3374, 3948, 2278, 1097, 2561, 1580, 1089,  593, 2736, 2642, 1296,\n",
       "       1831,  833, 2115, 2664, 2369,  788,  208, 2160, 1784,  235, 2671,\n",
       "        380, 1100,   32, 3763, 2344,  916, 2144, 2085, 2762, 2115, 1009,\n",
       "       1046, 1653, 3698, 2097, 2407, 2059, 2240,  434, 2657, 2289,   70,\n",
       "       1352, 1337, 1387, 3175,  813, 1193, 3101, 2557, 2873, 2396, 1263,\n",
       "       3160, 1302, 1208, 3224, 2918, 1892, 3882, 3481,  350, 2458, 1246,\n",
       "        680, 1379, 2344, 1397,  837, 1252,  471, 1244,  597, 3897, 3256,\n",
       "        468, 2724, 2546,  349, 1184,  761, 3543,  590, 1278, 2565, 2716,\n",
       "       1894, 2151, 3508, 3354,  412,  474, 1198,   36, 1307, 2700, 1330,\n",
       "        593, 3596, 2100, 2867,  480, 3030])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model_input = {name:train[name].values for name in feature_names}\n",
    "test_model_input = {name:test[name].values for name in feature_names}\n",
    "train_model_input['movie_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3ea894f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepFM(linear_feature_columns, dnn_feature_columns, task='regression')\n",
    "model.compile(\"adam\", \"mse\", metrics=['mse'], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e96caabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229810016"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 直接吃了177M内存\n",
    "asizeof.asizeof(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b09cfe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d9d68996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 128 samples, validate on 32 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bytedance/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/Users/bytedance/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 - 1s - loss: 13.4138 - mse: 13.4138 - val_loss: 15.7048 - val_mse: 15.7048\n",
      "Epoch 2/10\n",
      "128/128 - 0s - loss: 13.3058 - mse: 13.3058 - val_loss: 15.5908 - val_mse: 15.5908\n",
      "Epoch 3/10\n",
      "128/128 - 0s - loss: 13.1876 - mse: 13.1876 - val_loss: 15.4656 - val_mse: 15.4656\n",
      "Epoch 4/10\n",
      "128/128 - 0s - loss: 13.0572 - mse: 13.0572 - val_loss: 15.3296 - val_mse: 15.3296\n",
      "Epoch 5/10\n",
      "128/128 - 0s - loss: 12.9153 - mse: 12.9153 - val_loss: 15.1826 - val_mse: 15.1826\n",
      "Epoch 6/10\n",
      "128/128 - 0s - loss: 12.7613 - mse: 12.7613 - val_loss: 15.0241 - val_mse: 15.0241\n",
      "Epoch 7/10\n",
      "128/128 - 0s - loss: 12.5945 - mse: 12.5945 - val_loss: 14.8535 - val_mse: 14.8535\n",
      "Epoch 8/10\n",
      "128/128 - 0s - loss: 12.4140 - mse: 12.4140 - val_loss: 14.6699 - val_mse: 14.6699\n",
      "Epoch 9/10\n",
      "128/128 - 0s - loss: 12.2188 - mse: 12.2188 - val_loss: 14.4726 - val_mse: 14.4726\n",
      "Epoch 10/10\n",
      "128/128 - 0s - loss: 12.0078 - mse: 12.0078 - val_loss: 14.2607 - val_mse: 14.2607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f92dc633cc0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_model_input, train[\"rating\"].values, batch_size=256, epochs=10, verbose=2, validation_split=0.2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3f454f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24125732],\n",
       "       [0.17255694]], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model_input_v_test = {\n",
    "    \"movie_id\": np.array([1,2]),\n",
    "    \"user_id\": np.array([3,4])\n",
    "}\n",
    "model.predict(test_model_input_v_test, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a306a3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie_id': array([1485, 1884, 2420, 1945,    4, 3062, 2021, 3108, 1535,  540, 2918,\n",
       "        2690, 1960, 3102,   21, 1971, 1230, 3095, 1125, 3462,  218, 1019,\n",
       "         156, 2174, 3147,  367, 1792, 1196, 2799, 1242, 1221,  105,  590,\n",
       "         198, 3167, 3194, 3481, 1242, 1042, 1626]),\n",
       " 'user_id': array([ 877, 4238, 1579, 2002,  881, 3242, 1752, 3910, 1391, 3705, 3315,\n",
       "        3430, 4502, 5080, 5630, 1503, 3568, 1273, 2438, 5157,  546, 2067,\n",
       "        5788, 5511, 2600, 5108, 5039, 5227, 2996, 4738, 4715,  517, 4889,\n",
       "        5767, 4373, 5371,  380, 5746, 5365, 3868])}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aeedc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = [\"movie_id\", \"user_id\", \"gender\", \"age\", \"occupation\", \"zip\"]\n",
    "    target = ['rating']\n",
    "\n",
    "    # 1.Label Encoding for sparse features,and do simple Transformation for dense features\n",
    "    for feat in sparse_features:\n",
    "        lbe = LabelEncoder()\n",
    "        data[feat] = lbe.fit_transform(data[feat])\n",
    "    # 2.count #unique features for each sparse field\n",
    "    fixlen_feature_columns = [SparseFeat(feat, data[feat].max() + 1,embedding_dim=4)\n",
    "                              for feat in sparse_features]\n",
    "    linear_feature_columns = fixlen_feature_columns\n",
    "    dnn_feature_columns = fixlen_feature_columns\n",
    "    feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "\n",
    "    # 3.generate input data for model\n",
    "    train, test = train_test_split(data, test_size=0.2, random_state=2020)\n",
    "    train_model_input = {name:train[name].values for name in feature_names}\n",
    "    test_model_input = {name:test[name].values for name in feature_names}\n",
    "\n",
    "    # 4.Define Model,train,predict and evaluate\n",
    "    model = DeepFM(linear_feature_columns, dnn_feature_columns, task='regression')\n",
    "    model.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "\n",
    "    history = model.fit(train_model_input, train[target].values,\n",
    "                        batch_size=256, epochs=10, verbose=2, validation_split=0.2, )\n",
    "    pred_ans = model.predict(test_model_input, batch_size=256)\n",
    "    print(\"test MSE\", round(mean_squared_error(\n",
    "        test[target].values, pred_ans), 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
